{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ax.service.ax_client import AxClient\n",
    "from ax.modelbridge.generation_strategy import GenerationStrategy, GenerationStep\n",
    "from ax.modelbridge.registry import Models\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to view generation strategy on a given `AxClient` optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-05 07:39:43] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 2 decimal points.\n"
     ]
    }
   ],
   "source": [
    "ax_client = AxClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-05 07:40:22] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials]). Iterations after 5 will take longer to generate due to  model-fitting.\n"
     ]
    }
   ],
   "source": [
    "ax_client.create_experiment(\n",
    "    parameters=[{\"name\": \"x\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials])"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "bento_obj_id": "140029465076496"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax_client.generation_strategy  # To view the generation strategy summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GenerationStep(model=<Models.SOBOL: 'Sobol'>, num_trials=5, min_trials_observed=3, max_parallelism=None, use_update=False, enforce_num_trials=True, model_kwargs={'deduplicate': True, 'seed': None}, model_gen_kwargs=None, index=0),\n",
       " GenerationStep(model=<Models.GPEI: 'GPEI'>, num_trials=-1, min_trials_observed=0, max_parallelism=3, use_update=False, enforce_num_trials=True, model_kwargs=None, model_gen_kwargs=None, index=1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "bento_obj_id": "140029465083984"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax_client.generation_strategy._steps  # To view all the settings of the generation strategy steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1: Create custom generation strategy with all the same settings as would've been automatically chosen, but also with `model_kwargs` passed to the GPEI step\n",
    "Kwargs passed as `model_kwargs` are distributed between the underlying `Model` and `ModelBridge` according to their keyword names. To see what the available kwargs are, refer to the `model_class` and `bridge_class` properties of the `ModelSetup` corresponding to a given entry in the [`Models` registry enum](https://github.com/facebook/Ax/blob/master/ax/modelbridge/registry.py#L183). In this case, we will be passing kwargs to `Models.GPEI`, and the [corresponding `ModelSetup`](https://github.com/facebook/Ax/blob/master/ax/modelbridge/registry.py#L137-L142) includes `TorchModelBridge` as its model bridge and `BotorchModel` as its model. `TorchModelBridge` takes as kwargs `torch_dtype` and `torch_device` ([API docs](https://ax.dev/api/modelbridge.html#module-ax.modelbridge.torch), [source code](https://github.com/facebook/Ax/blob/master/ax/modelbridge/torch.py#L56-L57), so we will be passing those as `model_kwargs` to the corresponding generation step. Here is how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GenerationStrategy(\n",
    "    steps=[\n",
    "        # I omit a few settings when copying from the auto-selected generation strategy above, since those\n",
    "        # settings are just the defaults, but you can include them too if you'd like. Refer to the docs on\n",
    "        # `GenerationStep` for meanings of these settings: \n",
    "        # https://ax.dev/api/modelbridge.html#ax.modelbridge.generation_strategy.GenerationStep\n",
    "        GenerationStep(\n",
    "            model=Models.SOBOL, \n",
    "            num_trials=5, \n",
    "            min_trials_observed=3, \n",
    "            model_kwargs={'deduplicate': True, 'seed': None}, \n",
    "        ),\n",
    "        GenerationStep(\n",
    "            model=Models.GPEI,\n",
    "            num_trials=-1,\n",
    "            max_parallelism=3,  # Can set higher parallelism if needed\n",
    "            model_kwargs = {\"torch_dtype\": torch.float, \"torch_device\": torch.device(\"cuda\")}\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment': ax.core.experiment.Experiment,\n",
       " 'search_space': ax.core.search_space.SearchSpace,\n",
       " 'data': ax.core.data.Data,\n",
       " 'model': ax.models.torch_base.TorchModel,\n",
       " 'transforms': typing.List[typing.Type[ax.modelbridge.transforms.base.Transform]],\n",
       " 'transform_configs': typing.Union[typing.Dict[str, typing.Dict[str, typing.Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction]]], NoneType],\n",
       " 'torch_dtype': typing.Union[torch.dtype, NoneType],\n",
       " 'torch_device': typing.Union[torch.device, NoneType],\n",
       " 'status_quo_name': typing.Union[str, NoneType],\n",
       " 'status_quo_features': typing.Union[ax.core.observation.ObservationFeatures, NoneType],\n",
       " 'optimization_config': typing.Union[ax.core.optimization_config.OptimizationConfig, NoneType]}"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "bento_obj_id": "140029778954592"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also view the kwargs and their typing  for a given `Models` registry enum entry like so:\n",
    "model_kwargs, model_bridge_kwargs = Models.GPEI.view_kwargs()\n",
    "model_bridge_kwargs  # Showing the bridge kwargs, since those are what we are interested in in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we instantiate `AxClient` with our new generation strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-05 07:56:30] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 2 decimal points.\n"
     ]
    }
   ],
   "source": [
    "ax_client_with_custom_GS = AxClient(generation_strategy=gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax_client_with_custom_GS.create_experiment(\n",
    "    parameters=[{\"name\": \"x\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials])"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "bento_obj_id": "140029465077136"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax_client_with_custom_GS.generation_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GenerationStep(model=<Models.SOBOL: 'Sobol'>, num_trials=5, min_trials_observed=3, max_parallelism=None, use_update=False, enforce_num_trials=True, model_kwargs={'deduplicate': True, 'seed': None}, model_gen_kwargs=None, index=0),\n",
       " GenerationStep(model=<Models.GPEI: 'GPEI'>, num_trials=-1, min_trials_observed=0, max_parallelism=3, use_update=False, enforce_num_trials=True, model_kwargs={'torch_dtype': torch.float32, 'torch_device': device(type='cuda')}, model_gen_kwargs=None, index=1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "bento_obj_id": "140029465192560"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax_client_with_custom_GS.generation_strategy._steps  # Device and dtype settings are now propagated!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2: Hack existing generation strategy by replacing model kwargs directly in one of its steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-05 08:09:57] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 2 decimal points.\n"
     ]
    }
   ],
   "source": [
    "ax_client = AxClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-05 08:10:04] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials]). Iterations after 5 will take longer to generate due to  model-fitting.\n"
     ]
    }
   ],
   "source": [
    "ax_client.create_experiment(\n",
    "    parameters=[{\"name\": \"x\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationStep(model=<Models.GPEI: 'GPEI'>, num_trials=-1, min_trials_observed=0, max_parallelism=3, use_update=False, enforce_num_trials=True, model_kwargs={'torch_dtype': torch.float32, 'torch_device': device(type='cuda')}, model_gen_kwargs=None, index=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "bento_obj_id": "140029426661280"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax_client.generation_strategy._steps[1]._replace(  # We modify the original auto-selected generation strategy.\n",
    "    model_kwargs={\"torch_dtype\": torch.float, \"torch_device\": torch.device(\"cuda\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GenerationStep(model=<Models.SOBOL: 'Sobol'>, num_trials=5, min_trials_observed=3, max_parallelism=None, use_update=False, enforce_num_trials=True, model_kwargs={'deduplicate': True, 'seed': None}, model_gen_kwargs=None, index=0),\n",
       " GenerationStep(model=<Models.GPEI: 'GPEI'>, num_trials=-1, min_trials_observed=0, max_parallelism=3, use_update=False, enforce_num_trials=True, model_kwargs=None, model_gen_kwargs=None, index=1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "bento_obj_id": "140029465536064"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax_client.generation_strategy._steps  # Steps of the generation strategy are now modified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "Whether you choose solution 1 or 2, once you've set up your `AxClient` with a custom or modified generation strategy, you can start calling `ax_client.get_next_trial` as usual."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
